---
title: "Ontologies"
vignette: >
  %\VignetteIndexEntry{Ontologies}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
knitr:
  opts_chunk:
    collapse: true
    comment: '#>'
---

## Ontologies

`bixverse` also offers some methods that work on ontologies (think disease,
gene or phenotype ontologies) and leverages Rust for very fast calculations
of different similarity measures.

```{r}
#| label: setup
library(bixverse)
library(data.table)
library(magrittr)
library(zeallot)
```

### Data

In this case, we will be using the HPO from the the `ontologyIndex` package.

```{r}
#| label: loading in hpo
#| eval: !expr requireNamespace("ontologyIndex", quietly = TRUE)

library("ontologyIndex")

data("hpo")

hpo_data <- as.data.table(stack(hpo$children)) %>%
  setnames(old = c("values", "ind"), new = c("child", "parent")) %>%
  .[, c("parent", "child"), with = FALSE] %>%
  .[, type := "parent_of"] 
```

### Semantic similarities

Armed with the parent child data we can now calculate the semantic similarities.
First we need the ancestry to identify the ancestors and calculate the
information content. We can do this via: 

```{r}
#| label: get the ancestry and information content
c(ancestors, descendants) %<-% get_ontology_ancestry(hpo_data)

information_content <- calculate_information_content(descendants)
```

Armed with this, we can now calculate different semantic similarity matrices,
based on [Resnik](https://arxiv.org/abs/1105.5444) similarity, the 
Lin similarity and a combination of the two.

```{r}
#| label: resnik similarity calculation

resnik_similarity <- calculate_semantic_sim_mat(
  similarity_type = "resnik",
  ancestor_list = ancestors,
  ic_list = information_content
)

# The similarity is rescaled to between 0 and 1
resnik_similarity[1:5, 1:5]
```

To calculate the Lin similarity you can just do adopt the parameter:

```{r}
#| label: lin similarity calculation

lin_similarity <- calculate_semantic_sim_mat(
  similarity_type = "lin",
  ancestor_list = ancestors,
  ic_list = information_content
)

lin_similarity[1:5, 1:5]
```

Of course you can also just calculate the similarity between pre-specified
terms. Let's do this for a random sample and use the combined semantic 
similarity, i.e., the average of the (normalised) Resnik and Lin similarity.

```{r}
#| label: calculate for pre-specified terms

set.seed(10101L)

random_term_sample <- sort(sample(names(information_content), 10L))

combined_similarity <- calculate_semantic_sim(
  terms = random_term_sample,
  similarity_type = "combined",
  ancestor_list = ancestors,
  ic_list = information_content
)

combined_similarity[1:5, 1:5]
```

### Wang similarities

We provide also the calculation of the 
[Wang similarity](https://academic.oup.com/bioinformatics/article/23/10/1274/197095). 
These are based on the DAG of the respective ontology and allow you to assign a
weight to relationship. To calculate this, let's generate again the full
matrix

```{r}
#| label: calculate full wang similarity

# We are assigning a weight of 0.8 here... 
# In this ontology we only have one type of relationship, but for example
# in the Gene Ontology there are more of them
wang_weights <- setNames(0.8, "parent_of")

wang_similarity <- calculate_wang_sim_mat(
  parent_child_dt = hpo_data, 
  weight = wang_weights
)
```

```{r}
#| label: calculate full wang for subset

wang_similarity_subset <- calculate_wang_sim(
  terms = random_term_sample,
  parent_child_dt = hpo_data, 
  weight = wang_weights
)

# This one returns a data.table
head(wang_similarity_subset)
```